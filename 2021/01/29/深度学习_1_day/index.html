<!-- build time:Tue Mar 23 2021 21:16:56 GMT+0800 (ä¸­å›½æ ‡å‡†æ—¶é—´) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/imageshttps:/tenadmin.oss-cn-chengdu.aliyuncs.com/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><link rel="mask-icon" href="/images/logo.svg" color=""><link rel="manifest" href="/images/manifest.json"><meta name="msapplication-config" content="/images/browserconfig.xml"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Alan" href="http://47.97.229.110/rss.xml"><link rel="alternate" type="application/atom+xml" title="Alan" href="http://47.97.229.110/atom.xml"><link rel="alternate" type="application/json" title="Alan" href="http://47.97.229.110/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC%E2%80%99:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://47.97.229.110/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/"><title>æ·±åº¦å­¦ä¹ _1_day - äººå·¥æ™ºèƒ½ | Yume Shoka = Alan</title><meta name="generator" content="Hexo 5.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">æ·±åº¦å­¦ä¹ _1_day</h1><div class="meta"><span class="item" title="åˆ›å»ºæ—¶é—´ï¼š2021-01-29 21:39:01"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">å‘è¡¨äº</span> <time itemprop="dateCreated datePublished" datetime="2021-01-29T21:39:01+08:00">2021-01-29</time> </span><span class="item" title="æœ¬æ–‡å­—æ•°"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">æœ¬æ–‡å­—æ•°</span> <span>11k</span> <span class="text">å­—</span> </span><span class="item" title="é˜…è¯»æ—¶é•¿"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">é˜…è¯»æ—¶é•¿</span> <span>10 åˆ†é’Ÿ</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="åˆ‡æ¢å¯¼èˆªæ "><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Yume Shoka</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipey0a334j20zk0m8qpt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicit4jrvuj20zk0m8785.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipeyvx1d4j20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicitspjpbj20zk0m81ky.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipewkhf1zj20zk0m81kx.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipeu7txpzj20zk0m81kx.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">é¦–é¡µ</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="item" rel="index" title="åˆ†ç±»äº äººå·¥æ™ºèƒ½"><span itemprop="name">äººå·¥æ™ºèƒ½</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://47.97.229.110/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="John Doe"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Alan"></span><div class="body md" itemprop="articleBody"><p>åŸºäºäººè„¸çš„å¸¸è§è¡¨æƒ…è¯†åˆ«â€”â€”æ¨¡å‹æ­å»ºã€è®­ç»ƒä¸æµ‹è¯•<br>æ¨¡å‹æ­å»ºä¸è®­ç»ƒ</p><ol><li>æ•°æ®æ¥å£å‡†å¤‡</li><li>æ¨¡å‹å®šä¹‰</li><li>æ¨¡å‹è®­ç»ƒ</li></ol><p>æ¨¡å‹æµ‹è¯•</p><p>æœ¬ Task æ˜¯ã€åŸºäºäººè„¸çš„å¸¸è§è¡¨æƒ…è¯†åˆ«ã€è®­ç»ƒè¥çš„ç¬¬ 3 è¯¾ï¼Œå¦‚æœä½ æœªå­¦ä¹ å‰é¢çš„è¯¾ç¨‹ï¼Œè¯·ä» Task1 å¼€å§‹å­¦ä¹ ï¼Œæœ¬ Task éœ€è¦ä½¿ç”¨åˆ°æ•°æ®é›†ï¼Œåœ¨ Task2 ä¸­æä¾›ä¸‹è½½çš„æ¸ é“ã€‚</p><p>åœ¨å®Œæˆäº†æ•°æ®å‡†å¤‡åï¼Œæ¥ä¸‹æ¥å°±æ˜¯å·ç§¯ç¥ç»ç½‘ç»œä¸€å±•èº«æ‰‹çš„æ—¶å€™äº†ï¼Œé€šè¿‡æœ¬æ¬¡ä»»åŠ¡ï¼Œæ‚¨å°†å­¦åˆ°å¦‚ä½•ä½¿ç”¨ PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ç°å·ç§¯ç¥ç»ç½‘ç»œçš„å®šä¹‰ã€è®­ç»ƒå’Œé¢„æµ‹ã€‚</p><p>æ¨¡å‹æ­å»ºä¸è®­ç»ƒ<br>å¾—åˆ°äº†æ•°æ®ä¹‹åï¼Œæ¥ä¸‹æ¥å’±ä»¬ä½¿ç”¨ PyTorch è¿™ä¸ªæ¡†æ¶æ¥è¿›è¡Œæ¨¡å‹çš„è®­ç»ƒã€‚æ•´ä¸ªè®­ç»ƒæµç¨‹åŒ…æ‹¬æ•°æ®æ¥å£å‡†å¤‡ã€æ¨¡å‹å®šä¹‰ã€ç»“æœä¿å­˜ä¸åˆ†æã€‚</p><ol><li>æ•°æ®æ¥å£å‡†å¤‡<br>PyTorch å›¾åƒåˆ†ç±»ç›´æ¥åˆ©ç”¨æ–‡ä»¶å¤¹ä½œä¸ºè¾“å…¥ï¼Œåªéœ€è¦æŠŠä¸åŒç±»çš„æ•°æ®æ”¾åˆ°ä¸åŒçš„æ–‡ä»¶å¤¹ä¸­ã€‚æ•°æ®è¯»å–çš„å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š<pre><code class="python">data_transforms = &#123;
 &#39;train&#39;: transforms.Compose([
     transforms.RandomSizedCrop(48),
     transforms.RandomHorizontalFlip(),
     transforms.ToTensor(),
     transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
 ]),
 &#39;val&#39;: transforms.Compose([
     transforms.Scale(64),
     transforms.CenterCrop(48),
     transforms.ToTensor(),
     transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
 ]),
&#125;
</code></pre></li></ol><p>data_dir = â€˜./train_val_data/â€˜<br>image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),<br>data_transforms[x]) for x in [â€˜trainâ€™, â€˜valâ€™]}<br>dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],<br>batch_size=16,<br>shuffle=True,<br>num_workers=4) for x in [â€˜trainâ€™, â€˜valâ€™]}</p><pre><code>ä¸Šé¢è„šæœ¬ä¸­çš„å‡½æ•°ï¼Œè¾“å…¥ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œè¾“å‡ºå›¾ç‰‡è·¯å¾„ä»¥åŠæ ‡ç­¾ï¼Œåœ¨å¼€å§‹è®­ç»ƒä¹‹å‰éœ€è¦å°†æ•°æ®é›†è¿›è¡Œæ‹†åˆ†ï¼Œæ‹†åˆ†æˆè®­ç»ƒé›†(train)å’ŒéªŒè¯é›†(val)ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ¯”ä¾‹ä¸º9:1ï¼Œtrain_val_dataæ–‡ä»¶ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­ 0 ä»£è¡¨ noneã€ 1 ä»£è¡¨poutingã€2 ä»£è¡¨ smileã€3 ä»£è¡¨ openmouthï¼š
``` python
- train_val_data
    - train
        - 0
        - 1
        - 2
        - 3

    - val
        - 0
        - 1
        - 2
        - 3</code></pre><p>åˆ°æ­¤ï¼Œæ•°æ®æ¥å£å°±å®šä¹‰å®Œæ¯•äº†ï¼Œæ¥ä¸‹æ¥åœ¨è®­ç»ƒä»£ç ä¸­çœ‹å¦‚ä½•ä½¿ç”¨è¿­ä»£å™¨è¿›è¡Œæ•°æ®è¯»å–å°±å¯ä»¥äº†ã€‚</p><ol start="2"><li>æ¨¡å‹å®šä¹‰<br>åˆ›å»ºæ•°æ®æ¥â¼åï¼Œæˆ‘ä»¬å¼€å§‹å®šä¹‰â¼€ä¸ªâ½¹ç»œ simpleconv3<pre><code class="python">import torch.nn as nn
import torch.nn.functional as F
â€‹
class simpleconv3(nn.Module):
 def __init__(self):
     super(simpleconv3,self).__init__()
     self.conv1 = nn.Conv2d(3, 12, 3, 2)
     self.bn1 = nn.BatchNorm2d(12)
     self.conv2 = nn.Conv2d(12, 24, 3, 2)
     self.bn2 = nn.BatchNorm2d(24)
     self.conv3 = nn.Conv2d(24, 48, 3, 2)
     self.bn3 = nn.BatchNorm2d(48)
     self.fc1 = nn.Linear(48 * 5 * 5 , 1200)
     self.fc2 = nn.Linear(1200 , 128)
     self.fc3 = nn.Linear(128 , 4)
â€‹
 def forward(self , x):
     x = F.relu(self.bn1(self.conv1(x)))
     #print &quot;bn1 shape&quot;,x.shape
     x = F.relu(self.bn2(self.conv2(x)))
     x = F.relu(self.bn3(self.conv3(x)))
     x = x.view(-1 , 48 * 5 * 5) 
     x = F.relu(self.fc1(x))
     x = F.relu(self.fc2(x))
     x = self.fc3(x)
     return x</code></pre>ä¸Šé¢å°±æ˜¯æˆ‘ä»¬å®šä¹‰çš„ç½‘ç»œï¼Œæ˜¯ä¸€ä¸ªç®€å•çš„ 3 å±‚å·ç§¯ã€‚åœ¨ torch.nn ä¸‹ï¼Œæœ‰å„ç§ç½‘ç»œå±‚ï¼Œè¿™é‡Œå°±ç”¨åˆ°äº† nn.Conv2dï¼Œnn.BatchNorm2d å’Œ nn.Linearï¼Œåˆ†åˆ«æ˜¯å·ç§¯å±‚ï¼ŒBN å±‚å’Œå…¨è¿æ¥å±‚ã€‚æˆ‘ä»¬ä»¥ä¸€ä¸ªå·ç§¯å±‚ä¸ºä¾‹ï¼š</li></ol><p>conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=2)<br>bn1 = nn.BatchNorm2d(num_features=12)<br>in_channelsï¼šè¾“å…¥é€šé“æ•°<br>out_channelsï¼šè¾“å‡ºé€šé“æ•°<br>kernel_sizeï¼šå·ç§¯æ ¸çš„å¤§å°<br>strideï¼šå·ç§¯æ ¸çš„ç§»åŠ¨æ­¥é•¿<br>æ›´å…¨é¢çš„å‚æ•°ï¼Œè¯·è‡ªæŸ¥ APIï¼š<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">https://pytorch.org/</span></p><ol start="3"><li>æ¨¡å‹è®­ç»ƒ<br>è¿™é‡Œå‡†å¤‡å¥½äº†æ•°æ®é›†ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨</li></ol><p>æ·±åº¦å­¦ä¹ ä¸€èˆ¬ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒï¼Œå¤§å®¶å¯ä»¥æ ¹æ®ä¸‹å›¾çš„æ“ä½œï¼Œå°†è®¾å¤‡åˆ‡æ¢è‡³ GPUçŠ¶æ€ï¼Œå†è¿è¡Œä¸‹é¢çš„ç¨‹åºï¼Œåˆ‡æ¢è¿‡ç¨‹éœ€è¦ä¸€å®šæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…</p><p>Image</p><pre><code class="python">#coding:utf8
from __future__ import print_function, division
â€‹
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
import torchvision
from torchvision import datasets, models, transforms
import time
import os
from tensorboardX import SummaryWriter
import torch.nn.functional as F
import numpy as np
â€‹
import warnings
â€‹
warnings.filterwarnings(&#39;ignore&#39;)
â€‹
writer = SummaryWriter()
â€‹
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    for epoch in range(num_epochs):
        print(&#39;Epoch &#123;&#125;/&#123;&#125;&#39;.format(epoch, num_epochs - 1))
        for phase in [&#39;train&#39;, &#39;val&#39;]:
            if phase == &#39;train&#39;:
                scheduler.step()
                model.train(True)  # Set model to training mode
            else:
                model.train(False)  # Set model to evaluate mode
â€‹
            running_loss = 0.0
            running_corrects = 0.0
â€‹
            for data in dataloders[phase]:
                inputs, labels = data
                if use_gpu:
                    inputs = Variable(inputs.cuda())
                    labels = Variable(labels.cuda())
                else:
                    inputs, labels = Variable(inputs), Variable(labels)
â€‹
                optimizer.zero_grad()
                outputs = model(inputs)
                _, preds = torch.max(outputs.data, 1)
                loss = criterion(outputs, labels)
                if phase == &#39;train&#39;:
                    loss.backward()
                    optimizer.step()
â€‹
                running_loss += loss.data.item()
                running_corrects += torch.sum(preds == labels).item()
â€‹
            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects / dataset_sizes[phase]

            if phase == &#39;train&#39;:
                writer.add_scalar(&#39;data/trainloss&#39;, epoch_loss, epoch)
                writer.add_scalar(&#39;data/trainacc&#39;, epoch_acc, epoch)
            else:
                writer.add_scalar(&#39;data/valloss&#39;, epoch_loss, epoch)
                writer.add_scalar(&#39;data/valacc&#39;, epoch_acc, epoch)
â€‹
            print(&#39;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#39;.format(
                phase, epoch_loss, epoch_acc))
â€‹
    writer.export_scalars_to_json(&quot;./all_scalars.json&quot;)
    writer.close()
    return model
â€‹
if __name__ == &#39;__main__&#39;:
â€‹
    data_transforms = &#123;
        &#39;train&#39;: transforms.Compose([
            transforms.RandomSizedCrop(48),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
        ]),
        &#39;val&#39;: transforms.Compose([
            transforms.Scale(64),
            transforms.CenterCrop(48),
            transforms.ToTensor(),
            transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
        ]),
    &#125;
â€‹
    data_dir = &#39;./Emotion_Recognition_File/train_val_data/&#39; # æ•°æ®é›†æ‰€åœ¨çš„ä½ç½®
    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),
                                              data_transforms[x]) for x in [&#39;train&#39;, &#39;val&#39;]&#125;
    dataloders = &#123;x: torch.utils.data.DataLoader(image_datasets[x],
                                                 batch_size=64,
                                                 shuffle=True if x==&quot;train&quot; else False,
                                                 num_workers=8) for x in [&#39;train&#39;, &#39;val&#39;]&#125;
â€‹
    dataset_sizes = &#123;x: len(image_datasets[x]) for x in [&#39;train&#39;, &#39;val&#39;]&#125;
â€‹
    use_gpu = torch.cuda.is_available()
    print(&quot;æ˜¯å¦ä½¿ç”¨ GPU&quot;, use_gpu)
    modelclc = simpleconv3()
    print(modelclc)
    if use_gpu:
        modelclc = modelclc.cuda()
â€‹
    criterion = nn.CrossEntropyLoss()
    optimizer_ft = optim.SGD(modelclc.parameters(), lr=0.1, momentum=0.9)
    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=100, gamma=0.1)
â€‹
    modelclc = train_model(model=modelclc,
                           criterion=criterion,
                           optimizer=optimizer_ft,
                           scheduler=exp_lr_scheduler,
                           num_epochs=10)  # è¿™é‡Œå¯ä»¥è°ƒèŠ‚è®­ç»ƒçš„è½®æ¬¡
    if not os.path.exists(&quot;models&quot;):
        os.mkdir(&#39;models&#39;)
    torch.save(modelclc.state_dict(),&#39;models/model.ckpt&#39;)</code></pre><p>è®­ç»ƒçš„è¿‡ç¨‹éœ€è¦æ³¨æ„å‡ ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªæ˜¯æ•°æ®åŠ è½½å™¨(dataloders)ä¸­çš„ batch_sizeï¼Œè¿™ä¸ªä»£è¡¨çš„å«ä¹‰æ˜¯æ¯æ¬¡é€å…¥æ¨¡å‹è®­ç»ƒçš„å›¾ç‰‡æ•°é‡ï¼Œè¿™ä¸ªéœ€è¦æ ¹æ®GPUçš„æ˜¾å­˜æ¥è®¾ç½®ï¼Œæ˜¾å­˜è¶Šå¤§ï¼Œå¯ä»¥è®¾ç½®è¶Šå¤§ï¼Œè¿™ä¸ªæ•°ä¸€èˆ¬è®¾ç½®ä¸º 2 çš„æ•´æ•°æ¬¡å¹‚ï¼ˆå¦‚ 4ã€8ã€16ã€32 ç­‰ï¼‰</p><p>dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],<br>batch_size=64,<br>shuffle=True if x==â€trainâ€ else False,<br>num_workers=8) for x in [â€˜trainâ€™, â€˜valâ€™]}<br>ç¬¬äºŒä¸ªéœ€è¦æ³¨æ„çš„å‚æ•°æ˜¯è®­ç»ƒå‡½æ•°çš„ num_epochsï¼Œè¿™ä¸ªå‚æ•°ä»£è¡¨çš„æ„ä¹‰æ˜¯ï¼Œæ¨¡å‹è®­ç»ƒçš„è½®æ¬¡ã€‚</p><p>modelclc = train_model(model=modelclc,<br>criterion=criterion,<br>optimizer=optimizer_ft,<br>scheduler=exp_lr_scheduler,<br>num_epochs=10) # è¿™é‡Œå¯ä»¥è°ƒèŠ‚è®­ç»ƒçš„è½®æ¬¡<br>æ¨¡å‹æµ‹è¯•<br>ä¸Šâ¾¯å·²ç»è®­ç»ƒå¥½äº†æ¨¡å‹ï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥çš„â½¬æ ‡ï¼Œå°±æ˜¯è¦â½¤å®ƒæ¥åšæ¨ç†ï¼ŒçœŸæ­£æŠŠæ¨¡å‹â½¤èµ·æ¥ï¼Œä¸‹â¾¯æˆ‘ä»¬è½½â¼Šâ¼€ä¸ªå›¾â½šï¼Œâ½¤æ¨¡å‹è¿›â¾æµ‹è¯•ã€‚ ç»“æœåœ¨ results æ–‡ä»¶å¤¹ä¸­</p><pre><code class="python"># coding:utf8
â€‹
import sys
import numpy as np
import cv2
import os
import dlib
â€‹
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
import torchvision
from torchvision import datasets, models, transforms
import time
from PIL import Image
import torch.nn.functional as F
â€‹
import matplotlib.pyplot as plt
import warnings
â€‹
warnings.filterwarnings(&#39;ignore&#39;)
â€‹
â€‹
PREDICTOR_PATH = &quot;./Emotion_Recognition_File/face_detect_model/shape_predictor_68_face_landmarks.dat&quot;
predictor = dlib.shape_predictor(PREDICTOR_PATH)
cascade_path = &#39;./Emotion_Recognition_File/face_detect_model/haarcascade_frontalface_default.xml&#39;
cascade = cv2.CascadeClassifier(cascade_path)
â€‹
if not os.path.exists(&quot;results&quot;):
    os.mkdir(&quot;results&quot;)

â€‹
def standardization(data):
    mu = np.mean(data, axis=0)
    sigma = np.std(data, axis=0)
    return (data - mu) / sigma
â€‹
â€‹
def get_landmarks(im):
    rects = cascade.detectMultiScale(im, 1.3, 5)
    x, y, w, h = rects[0]
    rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))
    return np.matrix([[p.x, p.y] for p in predictor(im, rect).parts()])
â€‹
â€‹
def annotate_landmarks(im, landmarks):
    im = im.copy()
    for idx, point in enumerate(landmarks):
        pos = (point[0, 0], point[0, 1])
        cv2.putText(im,
                    str(idx),
                    pos,
                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,
                    fontScale=0.4,
                    color=(0, 0, 255))
        cv2.circle(im, pos, 3, color=(0, 255, 255))
    return im
â€‹
â€‹
testsize = 48  # æµ‹è¯•å›¾å¤§å°
â€‹
data_transforms = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])
net = simpleconv3()
net.eval()
modelpath = &quot;./models/model.ckpt&quot;  # æ¨¡å‹è·¯å¾„
net.load_state_dict(
    torch.load(modelpath, map_location=lambda storage, loc: storage))
â€‹
# ä¸€æ¬¡æµ‹è¯•ä¸€ä¸ªæ–‡ä»¶
img_path = &quot;./Emotion_Recognition_File/find_face_img/&quot;
imagepaths = os.listdir(img_path)  # å›¾åƒæ–‡ä»¶å¤¹
for imagepath in imagepaths:
    im = cv2.imread(os.path.join(img_path, imagepath), 1)
    try:
        rects = cascade.detectMultiScale(im, 1.3, 5)
        x, y, w, h = rects[0]
        rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))
        landmarks = np.matrix([[p.x, p.y]
                               for p in predictor(im, rect).parts()])
    except:
#         print(&quot;æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸&quot;)
        continue  # æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸
â€‹
    xmin = 10000
    xmax = 0
    ymin = 10000
    ymax = 0
â€‹
    for i in range(48, 67):
        x = landmarks[i, 0]
        y = landmarks[i, 1]
        if x &lt; xmin:
            xmin = x
        if x &gt; xmax:
            xmax = x
        if y &lt; ymin:
            ymin = y
        if y &gt; ymax:
            ymax = y
â€‹
    roiwidth = xmax - xmin
    roiheight = ymax - ymin
â€‹
    roi = im[ymin:ymax, xmin:xmax, 0:3]
â€‹
    if roiwidth &gt; roiheight:
        dstlen = 1.5 * roiwidth
    else:
        dstlen = 1.5 * roiheight
â€‹
    diff_xlen = dstlen - roiwidth
    diff_ylen = dstlen - roiheight
â€‹
    newx = xmin
    newy = ymin
â€‹
    imagerows, imagecols, channel = im.shape
    if newx &gt;= diff_xlen / 2 and newx + roiwidth + diff_xlen / 2 &lt; imagecols:
        newx = newx - diff_xlen / 2
    elif newx &lt; diff_xlen / 2:
        newx = 0
    else:
        newx = imagecols - dstlen
â€‹
    if newy &gt;= diff_ylen / 2 and newy + roiheight + diff_ylen / 2 &lt; imagerows:
        newy = newy - diff_ylen / 2
    elif newy &lt; diff_ylen / 2:
        newy = 0
    else:
        newy = imagecols - dstlen
â€‹
    roi = im[int(newy):int(newy + dstlen), int(newx):int(newx + dstlen), 0:3]
    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
    roiresized = cv2.resize(roi,
                            (testsize, testsize)).astype(np.float32) / 255.0
    imgblob = data_transforms(roiresized).unsqueeze(0)
    imgblob.requires_grad = False
    imgblob = Variable(imgblob)
    torch.no_grad()
    predict = F.softmax(net(imgblob))
    print(predict)
    index = np.argmax(predict.detach().numpy())
â€‹
    im_show = cv2.imread(os.path.join(img_path, imagepath), 1)
    im_h, im_w, im_c = im_show.shape
    pos_x = int(newx + dstlen)
    pos_y = int(newy + dstlen)
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.rectangle(im_show, (int(newx), int(newy)),
                  (int(newx + dstlen), int(newy + dstlen)), (0, 255, 255), 2)
    if index == 0:
        cv2.putText(im_show, &#39;none&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
    if index == 1:
        cv2.putText(im_show, &#39;pout&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
    if index == 2:
        cv2.putText(im_show, &#39;smile&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
    if index == 3:
        cv2.putText(im_show, &#39;open&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
#     cv2.namedWindow(&#39;result&#39;, 0)
#     cv2.imshow(&#39;result&#39;, im_show)
    cv2.imwrite(os.path.join(&#39;results&#39;, imagepath), im_show)
#     print(os.path.join(&#39;results&#39;, imagepath))
    plt.imshow(im_show[:, :, ::-1])  # è¿™é‡Œéœ€è¦äº¤æ¢é€šé“ï¼Œå› ä¸º matplotlib ä¿å­˜å›¾ç‰‡çš„é€šé“é¡ºåºæ˜¯ RGBï¼Œè€Œåœ¨ OpenCV ä¸­æ˜¯ BGR
    plt.show()
#     cv2.waitKey(0)
# cv2.destroyAllWindows()
tensor([[8.1330e-03, 6.7033e-04, 9.8497e-01, 6.2311e-03]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[1.0822e-06, 1.9005e-09, 1.0000e+00, 2.3623e-07]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[9.9190e-01, 3.7207e-03, 4.3589e-03, 1.5936e-05]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[4.3434e-07, 1.2525e-06, 1.1251e-05, 9.9999e-01]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[0.0899, 0.8970, 0.0115, 0.0016]], grad_fn=&lt;SoftmaxBackward&gt;)</code></pre><p>å†æ¬¡è¯´æ˜ï¼š0 ä»£è¡¨ noneã€ 1 ä»£è¡¨poutingã€2 ä»£è¡¨ smileã€3 ä»£è¡¨ openmouth</p><p>ä¸Šé¢å±•ç¤ºçš„å›¾ç‰‡ä¸Šæ–¹ä¼šæœ‰ä¸€ä¸ªè¾“å‡ºï¼Œå¦‚ï¼štensor([[8.1330e-03, 6.7033e-04, 9.8497e-01, 6.2311e-03]])</p><p>è¿™ä¸ªä»£è¡¨çš„å«ä¹‰æ˜¯ï¼Œè¯¥å›¾ç‰‡åœ¨è¿™ä¸ªæ¨¡å‹é¢„æµ‹ä¸‹ï¼Œæ˜¯è¯¥ç±»åˆ«çš„å¯èƒ½æ€§ï¼Œæ¯”å¦‚ä¸Šé¢è¿™ä¸ªä¾‹å­ 9.8497e-01 æ˜¯å››ä¸ªå€¼æœ€å¤§çš„ï¼Œå®ƒçš„ç´¢å¼•æ˜¯ 2ï¼ˆä» 0 å¼€å§‹ç®—ï¼‰ï¼Œæ‰€ä»¥é¢„æµ‹è¯¥å›¾ç‰‡ä¸º smile</p><p>ä»¥ä¸Šå°±æ˜¯æœ¬è®­ç»ƒè¥çš„å…¨éƒ¨å†…å®¹äº†ï¼Œå¸Œæœ›é€šè¿‡æœ¬æ¬¡è®­ç»ƒè¥ï¼Œå¯ä»¥å¸®åŠ©å¤§å®¶æ­å»ºèµ·ä¸€ä¸ªæ·±åº¦å­¦ä¹ é¡¹ç›®çš„æ¡†æ¶ï¼Œç„¶åå°†æ‰€å­¦çš„çŸ¥è¯†åº”ç”¨åˆ°è‡ªå·±çš„é¡¹ç›®ã€å·¥ä½œä¸­ã€‚è°¢è°¢ï¼</p><p>â€“ Byï¼šæœ‰ä¸‰AI å›¢é˜Ÿ</p><p>èšç„¦äºè®©å¤§å®¶èƒ½å¤Ÿç³»ç»Ÿæ€§åœ°å®ŒæˆAIå„ä¸ªé¢†åŸŸæ‰€éœ€çš„ä¸“ä¸šçŸ¥è¯†çš„å­¦ä¹ ï¼Œå®ç°ä¸‰äººè¡Œå¿…æœ‰AIï¼Œä¸‰äººè¡Œå¿…æœ‰æˆ‘å¸ˆçš„æ„¿æ™¯ã€‚</p></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">æ›´æ–°äº</span> <time title="ä¿®æ”¹æ—¶é—´ï¼š2021-02-22 20:35:34" itemprop="dateModified" datetime="2021-02-22T20:35:34+08:00">2021-02-22</time> </span><span id="2021/01/29/æ·±åº¦å­¦ä¹ _1_day/" class="item leancloud_visitors" data-flag-title="æ·±åº¦å­¦ä¹ _1_day" title="é˜…è¯»æ¬¡æ•°"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">é˜…è¯»æ¬¡æ•°</span> <span class="leancloud-visitors-count"></span> <span class="text">æ¬¡</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> èµèµ</button><p>è¯·æˆ‘å–[èŒ¶]~(ï¿£â–½ï¿£)~*</p><div id="qr"><div><img data-src="/images/wechatpay.jpg" alt="John Doe å¾®ä¿¡æ”¯ä»˜"><p>å¾®ä¿¡æ”¯ä»˜</p></div><div><img data-src="/images/alipay.jpg" alt="John Doe æ”¯ä»˜å®"><p>æ”¯ä»˜å®</p></div></div></div><div id="copyright"><ul><li class="author"><strong>æœ¬æ–‡åšä¸»ï¼š </strong>John Doe <i class="ic i-at"><em>@</em></i>Alan</li><li class="link"><strong>æœ¬æ–‡é“¾æ¥ï¼š</strong> <a href="http://47.97.229.110/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/" title="æ·±åº¦å­¦ä¹ _1_day">http://47.97.229.110/2021/01/29/æ·±åº¦å­¦ä¹ _1_day/</a></li><li class="license"><strong>ç‰ˆæƒå£°æ˜ï¼š </strong>æœ¬ç«™æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2021/01/29/python-2-day/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipevo9j1jj20zk0m8e81.jpg" title="python_2_day"><span class="type">ä¸Šä¸€ç¯‡</span> <span class="category"><i class="ic i-flag"></i> Python</span><h3>python_2_day</h3></a></div><div class="item right"><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3-day/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gicitht3xtj20zk0m8k5v.jpg" title="æ·±åº¦å­¦ä¹ _3_day"><span class="type">ä¸‹ä¸€ç¯‡</span> <span class="category"><i class="ic i-flag"></i> äººå·¥æ™ºèƒ½</span><h3>æ·±åº¦å­¦ä¹ _3_day</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="æ–‡ç« ç›®å½•"></div><div class="related panel pjax" data-title="ç³»åˆ—æ–‡ç« "><ul><li><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2-day/" rel="bookmark" title="æ·±åº¦å­¦ä¹ _2_day">æ·±åº¦å­¦ä¹ _2_day</a></li><li><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3-day/" rel="bookmark" title="æ·±åº¦å­¦ä¹ _3_day">æ·±åº¦å­¦ä¹ _3_day</a></li><li class="active"><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/" rel="bookmark" title="æ·±åº¦å­¦ä¹ _1_day">æ·±åº¦å­¦ä¹ _1_day</a></li></ul></div><div class="overview panel" data-title="ç«™ç‚¹æ¦‚è§ˆ"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="John Doe" data-src="/images/avatar.jpg"><p class="name" itemprop="name">John Doe</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">20</span> <span class="name">æ–‡ç« </span></a></div><div class="item categories"><a href="/categories/"><span class="count">10</span> <span class="name">åˆ†ç±»</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0FsYW5vc3k=" title="https:&#x2F;&#x2F;github.com&#x2F;Alanosy"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cDovL3d3dy56aGlodS5jb20vcGVvcGxlL3dhbmctemhlbmctODEtNDQtOTM=" title="http:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;wang-zheng-81-44-93"><i class="ic i-zhihu"></i></span> <span class="exturl item email" data-url="bWFpbHRvOkFsYW5vc0BhbGl5dW4uY29t" title="mailto:Alanos@aliyun.com"><i class="ic i-envelope"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20vdS83NTMwMzcwODEx" title="https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;7530370811"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS9iaXRj" title="https:&#x2F;&#x2F;about.me&#x2F;bitc"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>é¦–é¡µ</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>æ–‡ç« </a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>å½’æ¡£</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>åˆ†ç±»</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>links</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>å…³äº</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2021/01/29/python-2-day/" rel="prev" title="ä¸Šä¸€ç¯‡"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3-day/" rel="next" title="ä¸‹ä¸€ç¯‡"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>éšæœºæ–‡ç« </h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="åˆ†ç±»äº äººå·¥æ™ºèƒ½">äººå·¥æ™ºèƒ½</a></div><span><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2-day/" title="æ·±åº¦å­¦ä¹ _2_day">æ·±åº¦å­¦ä¹ _2_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%97%A5%E5%BF%97/" title="åˆ†ç±»äº æ—¥å¿—">æ—¥å¿—</a></div><span><a href="/2021/01/26/2020-1-26/" title="2020-1-26">2020-1-26</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Html/" title="åˆ†ç±»äº Html">Html</a></div><span><a href="/2021/01/29/html_1day/" title="html_1_day">html_1_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%97%A5%E5%B8%B8/" title="åˆ†ç±»äº æ—¥å¸¸">æ—¥å¸¸</a></div><span><a href="/2021/03/15/103%E7%9A%84%E6%97%A5%E5%B8%B8%E7%94%9F%E6%B4%BB/" title="103å¯å®¤çš„æ—¥å¸¸">103å¯å®¤çš„æ—¥å¸¸</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="åˆ†ç±»äº äººå·¥æ™ºèƒ½">äººå·¥æ™ºèƒ½</a></div><span><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3-day/" title="æ·±åº¦å­¦ä¹ _3_day">æ·±åº¦å­¦ä¹ _3_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ython/" title="åˆ†ç±»äº ython">ython</a></div><span><a href="/2021/01/29/python-3-day/" title="python_3_day">python_3_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Hexo/" title="åˆ†ç±»äº Hexo">Hexo</a></div><span><a href="/2021/01/26/%E7%89%B9%E6%AE%8A%E5%8A%9F%E8%83%BD/" title="ç‰¹æ®ŠåŠŸèƒ½">ç‰¹æ®ŠåŠŸèƒ½</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Hexo/" title="åˆ†ç±»äº Hexo">Hexo</a></div><span><a href="/2021/03/13/hello-world/" title="Hello Hexo">Hello Hexo</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Html/" title="åˆ†ç±»äº Html">Html</a></div><span><a href="/2021/01/29/html_3day/" title="html_2_day">html_2_day</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2021/03/13/%E5%85%B3%E4%BA%8E/" title="å…³äº">å…³äº</a></span></li></ul></div><div><h2>æœ€æ–°è¯„è®º</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 â€“ <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">John Doe @ Yume Shoka</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="ç«™ç‚¹æ€»å­—æ•°">148k å­—</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">2:15</span></div><div class="powered-by">åŸºäº <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2021/01/29/æ·±åº¦å­¦ä¹ _1_day/",favicon:{show:"ï¼ˆâ—Â´3ï½€â—ï¼‰ã‚„ã‚Œã‚„ã‚Œã ãœ",hide:"(Â´Ğ”ï½€)å¤§å¤‰ã ï¼"},search:{placeholder:"æ–‡ç« æœç´¢",empty:"å…³äº ã€Œ ${query} ã€ï¼Œä»€ä¹ˆä¹Ÿæ²¡æœåˆ°",stats:"${time} ms å†…æ‰¾åˆ° ${hits} æ¡ç»“æœ"},valine:{placeholder:"1. æé—®å‰è¯·å…ˆä»”ç»†é˜…è¯»æœ¬æ–‡æ¡£âš¡\n2. é¡µé¢æ˜¾ç¤ºé—®é¢˜ğŸ’¥ï¼Œè¯·æä¾›æ§åˆ¶å°æˆªå›¾ğŸ“¸æˆ–è€…æ‚¨çš„æµ‹è¯•ç½‘å€\n3. å…¶ä»–ä»»ä½•æŠ¥é”™ğŸ’£ï¼Œè¯·æä¾›è¯¦ç»†æè¿°å’Œæˆªå›¾ğŸ“¸ï¼Œç¥é£Ÿç”¨æ„‰å¿«ğŸ’ª"},fancybox:!0,copyright:'å¤åˆ¶æˆåŠŸï¼Œè½¬è½½è¯·éµå®ˆ <i class="ic i-creative-commons"></i>BY-NC-SA åè®®ã€‚',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->