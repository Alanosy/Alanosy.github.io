<!-- build time:Mon Feb 22 2021 12:20:32 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/imageshttps:/tenadmin.oss-cn-chengdu.aliyuncs.com/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><link rel="mask-icon" href="/images/logo.svg" color=""><link rel="manifest" href="/images/manifest.json"><meta name="msapplication-config" content="/images/browserconfig.xml"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Alan" href="http://47.97.229.110/rss.xml"><link rel="alternate" type="application/atom+xml" title="Alan" href="http://47.97.229.110/atom.xml"><link rel="alternate" type="application/json" title="Alan" href="http://47.97.229.110/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC%E2%80%99:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://47.97.229.110/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/"><title>深度学习_1_day - 人工智能 | Yume Shoka = Alan</title><meta name="generator" content="Hexo 5.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">深度学习_1_day</h1><div class="meta"><span class="item" title="创建时间：2021-01-29 21:39:01"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2021-01-29T21:39:01+08:00">2021-01-29</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>11k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>10 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Yume Shoka</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipex2cdtbj20zk0m8x6p.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipeyvx1d4j20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giclxp31goj20zk0m8qv5.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipeuv80yoj20zk0m8kjl.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giclize41wj20zk0m87gk.jpg"></li><li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipeudstjqj20zk0m8k3r.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="item" rel="index" title="分类于 人工智能"><span itemprop="name">人工智能</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://47.97.229.110/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="John Doe"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Alan"></span><div class="body md" itemprop="articleBody"><p>基于人脸的常见表情识别——模型搭建、训练与测试<br>模型搭建与训练</p><ol><li>数据接口准备</li><li>模型定义</li><li>模型训练</li></ol><p>模型测试</p><p>本 Task 是『基于人脸的常见表情识别』训练营的第 3 课，如果你未学习前面的课程，请从 Task1 开始学习，本 Task 需要使用到数据集，在 Task2 中提供下载的渠道。</p><p>在完成了数据准备后，接下来就是卷积神经网络一展身手的时候了，通过本次任务，您将学到如何使用 PyTorch 深度学习框架，实现卷积神经网络的定义、训练和预测。</p><p>模型搭建与训练<br>得到了数据之后，接下来咱们使用 PyTorch 这个框架来进行模型的训练。整个训练流程包括数据接口准备、模型定义、结果保存与分析。</p><ol><li>数据接口准备<br>PyTorch 图像分类直接利用文件夹作为输入，只需要把不同类的数据放到不同的文件夹中。数据读取的完整代码如下：<pre><code class="python">data_transforms = &#123;
 &#39;train&#39;: transforms.Compose([
     transforms.RandomSizedCrop(48),
     transforms.RandomHorizontalFlip(),
     transforms.ToTensor(),
     transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
 ]),
 &#39;val&#39;: transforms.Compose([
     transforms.Scale(64),
     transforms.CenterCrop(48),
     transforms.ToTensor(),
     transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
 ]),
&#125;
</code></pre></li></ol><p>data_dir = ‘./train_val_data/‘<br>image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),<br>data_transforms[x]) for x in [‘train’, ‘val’]}<br>dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],<br>batch_size=16,<br>shuffle=True,<br>num_workers=4) for x in [‘train’, ‘val’]}</p><pre><code>上面脚本中的函数，输入一个文件夹，输出图片路径以及标签，在开始训练之前需要将数据集进行拆分，拆分成训练集(train)和验证集(val)，训练集和测试集的比例为9:1，train_val_data文件结构如下所示，其中 0 代表 none、 1 代表pouting、2 代表 smile、3 代表 openmouth：
``` python
- train_val_data
    - train
        - 0
        - 1
        - 2
        - 3

    - val
        - 0
        - 1
        - 2
        - 3</code></pre><p>到此，数据接口就定义完毕了，接下来在训练代码中看如何使用迭代器进行数据读取就可以了。</p><ol start="2"><li>模型定义<br>创建数据接⼝后，我们开始定义⼀个⽹络 simpleconv3<pre><code class="python">import torch.nn as nn
import torch.nn.functional as F
​
class simpleconv3(nn.Module):
 def __init__(self):
     super(simpleconv3,self).__init__()
     self.conv1 = nn.Conv2d(3, 12, 3, 2)
     self.bn1 = nn.BatchNorm2d(12)
     self.conv2 = nn.Conv2d(12, 24, 3, 2)
     self.bn2 = nn.BatchNorm2d(24)
     self.conv3 = nn.Conv2d(24, 48, 3, 2)
     self.bn3 = nn.BatchNorm2d(48)
     self.fc1 = nn.Linear(48 * 5 * 5 , 1200)
     self.fc2 = nn.Linear(1200 , 128)
     self.fc3 = nn.Linear(128 , 4)
​
 def forward(self , x):
     x = F.relu(self.bn1(self.conv1(x)))
     #print &quot;bn1 shape&quot;,x.shape
     x = F.relu(self.bn2(self.conv2(x)))
     x = F.relu(self.bn3(self.conv3(x)))
     x = x.view(-1 , 48 * 5 * 5) 
     x = F.relu(self.fc1(x))
     x = F.relu(self.fc2(x))
     x = self.fc3(x)
     return x</code></pre>上面就是我们定义的网络，是一个简单的 3 层卷积。在 torch.nn 下，有各种网络层，这里就用到了 nn.Conv2d，nn.BatchNorm2d 和 nn.Linear，分别是卷积层，BN 层和全连接层。我们以一个卷积层为例：</li></ol><p>conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=2)<br>bn1 = nn.BatchNorm2d(num_features=12)<br>in_channels：输入通道数<br>out_channels：输出通道数<br>kernel_size：卷积核的大小<br>stride：卷积核的移动步长<br>更全面的参数，请自查 API：<span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy8=">https://pytorch.org/</span></p><ol start="3"><li>模型训练<br>这里准备好了数据集，可以直接使用</li></ol><p>深度学习一般使用 GPU 进行训练，大家可以根据下图的操作，将设备切换至 GPU状态，再运行下面的程序，切换过程需要一定时间，请耐心等待</p><p>Image</p><pre><code class="python">#coding:utf8
from __future__ import print_function, division
​
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
import torchvision
from torchvision import datasets, models, transforms
import time
import os
from tensorboardX import SummaryWriter
import torch.nn.functional as F
import numpy as np
​
import warnings
​
warnings.filterwarnings(&#39;ignore&#39;)
​
writer = SummaryWriter()
​
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    for epoch in range(num_epochs):
        print(&#39;Epoch &#123;&#125;/&#123;&#125;&#39;.format(epoch, num_epochs - 1))
        for phase in [&#39;train&#39;, &#39;val&#39;]:
            if phase == &#39;train&#39;:
                scheduler.step()
                model.train(True)  # Set model to training mode
            else:
                model.train(False)  # Set model to evaluate mode
​
            running_loss = 0.0
            running_corrects = 0.0
​
            for data in dataloders[phase]:
                inputs, labels = data
                if use_gpu:
                    inputs = Variable(inputs.cuda())
                    labels = Variable(labels.cuda())
                else:
                    inputs, labels = Variable(inputs), Variable(labels)
​
                optimizer.zero_grad()
                outputs = model(inputs)
                _, preds = torch.max(outputs.data, 1)
                loss = criterion(outputs, labels)
                if phase == &#39;train&#39;:
                    loss.backward()
                    optimizer.step()
​
                running_loss += loss.data.item()
                running_corrects += torch.sum(preds == labels).item()
​
            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects / dataset_sizes[phase]

            if phase == &#39;train&#39;:
                writer.add_scalar(&#39;data/trainloss&#39;, epoch_loss, epoch)
                writer.add_scalar(&#39;data/trainacc&#39;, epoch_acc, epoch)
            else:
                writer.add_scalar(&#39;data/valloss&#39;, epoch_loss, epoch)
                writer.add_scalar(&#39;data/valacc&#39;, epoch_acc, epoch)
​
            print(&#39;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#39;.format(
                phase, epoch_loss, epoch_acc))
​
    writer.export_scalars_to_json(&quot;./all_scalars.json&quot;)
    writer.close()
    return model
​
if __name__ == &#39;__main__&#39;:
​
    data_transforms = &#123;
        &#39;train&#39;: transforms.Compose([
            transforms.RandomSizedCrop(48),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
        ]),
        &#39;val&#39;: transforms.Compose([
            transforms.Scale(64),
            transforms.CenterCrop(48),
            transforms.ToTensor(),
            transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])
        ]),
    &#125;
​
    data_dir = &#39;./Emotion_Recognition_File/train_val_data/&#39; # 数据集所在的位置
    image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),
                                              data_transforms[x]) for x in [&#39;train&#39;, &#39;val&#39;]&#125;
    dataloders = &#123;x: torch.utils.data.DataLoader(image_datasets[x],
                                                 batch_size=64,
                                                 shuffle=True if x==&quot;train&quot; else False,
                                                 num_workers=8) for x in [&#39;train&#39;, &#39;val&#39;]&#125;
​
    dataset_sizes = &#123;x: len(image_datasets[x]) for x in [&#39;train&#39;, &#39;val&#39;]&#125;
​
    use_gpu = torch.cuda.is_available()
    print(&quot;是否使用 GPU&quot;, use_gpu)
    modelclc = simpleconv3()
    print(modelclc)
    if use_gpu:
        modelclc = modelclc.cuda()
​
    criterion = nn.CrossEntropyLoss()
    optimizer_ft = optim.SGD(modelclc.parameters(), lr=0.1, momentum=0.9)
    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=100, gamma=0.1)
​
    modelclc = train_model(model=modelclc,
                           criterion=criterion,
                           optimizer=optimizer_ft,
                           scheduler=exp_lr_scheduler,
                           num_epochs=10)  # 这里可以调节训练的轮次
    if not os.path.exists(&quot;models&quot;):
        os.mkdir(&#39;models&#39;)
    torch.save(modelclc.state_dict(),&#39;models/model.ckpt&#39;)</code></pre><p>训练的过程需要注意几个参数，第一个是数据加载器(dataloders)中的 batch_size，这个代表的含义是每次送入模型训练的图片数量，这个需要根据GPU的显存来设置，显存越大，可以设置越大，这个数一般设置为 2 的整数次幂（如 4、8、16、32 等）</p><p>dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],<br>batch_size=64,<br>shuffle=True if x==”train” else False,<br>num_workers=8) for x in [‘train’, ‘val’]}<br>第二个需要注意的参数是训练函数的 num_epochs，这个参数代表的意义是，模型训练的轮次。</p><p>modelclc = train_model(model=modelclc,<br>criterion=criterion,<br>optimizer=optimizer_ft,<br>scheduler=exp_lr_scheduler,<br>num_epochs=10) # 这里可以调节训练的轮次<br>模型测试<br>上⾯已经训练好了模型，我们接下来的⽬标，就是要⽤它来做推理，真正把模型⽤起来，下⾯我们载⼊⼀个图⽚，⽤模型进⾏测试。 结果在 results 文件夹中</p><pre><code class="python"># coding:utf8
​
import sys
import numpy as np
import cv2
import os
import dlib
​
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
import torchvision
from torchvision import datasets, models, transforms
import time
from PIL import Image
import torch.nn.functional as F
​
import matplotlib.pyplot as plt
import warnings
​
warnings.filterwarnings(&#39;ignore&#39;)
​
​
PREDICTOR_PATH = &quot;./Emotion_Recognition_File/face_detect_model/shape_predictor_68_face_landmarks.dat&quot;
predictor = dlib.shape_predictor(PREDICTOR_PATH)
cascade_path = &#39;./Emotion_Recognition_File/face_detect_model/haarcascade_frontalface_default.xml&#39;
cascade = cv2.CascadeClassifier(cascade_path)
​
if not os.path.exists(&quot;results&quot;):
    os.mkdir(&quot;results&quot;)

​
def standardization(data):
    mu = np.mean(data, axis=0)
    sigma = np.std(data, axis=0)
    return (data - mu) / sigma
​
​
def get_landmarks(im):
    rects = cascade.detectMultiScale(im, 1.3, 5)
    x, y, w, h = rects[0]
    rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))
    return np.matrix([[p.x, p.y] for p in predictor(im, rect).parts()])
​
​
def annotate_landmarks(im, landmarks):
    im = im.copy()
    for idx, point in enumerate(landmarks):
        pos = (point[0, 0], point[0, 1])
        cv2.putText(im,
                    str(idx),
                    pos,
                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,
                    fontScale=0.4,
                    color=(0, 0, 255))
        cv2.circle(im, pos, 3, color=(0, 255, 255))
    return im
​
​
testsize = 48  # 测试图大小
​
data_transforms = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])
net = simpleconv3()
net.eval()
modelpath = &quot;./models/model.ckpt&quot;  # 模型路径
net.load_state_dict(
    torch.load(modelpath, map_location=lambda storage, loc: storage))
​
# 一次测试一个文件
img_path = &quot;./Emotion_Recognition_File/find_face_img/&quot;
imagepaths = os.listdir(img_path)  # 图像文件夹
for imagepath in imagepaths:
    im = cv2.imread(os.path.join(img_path, imagepath), 1)
    try:
        rects = cascade.detectMultiScale(im, 1.3, 5)
        x, y, w, h = rects[0]
        rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))
        landmarks = np.matrix([[p.x, p.y]
                               for p in predictor(im, rect).parts()])
    except:
#         print(&quot;没有检测到人脸&quot;)
        continue  # 没有检测到人脸
​
    xmin = 10000
    xmax = 0
    ymin = 10000
    ymax = 0
​
    for i in range(48, 67):
        x = landmarks[i, 0]
        y = landmarks[i, 1]
        if x &lt; xmin:
            xmin = x
        if x &gt; xmax:
            xmax = x
        if y &lt; ymin:
            ymin = y
        if y &gt; ymax:
            ymax = y
​
    roiwidth = xmax - xmin
    roiheight = ymax - ymin
​
    roi = im[ymin:ymax, xmin:xmax, 0:3]
​
    if roiwidth &gt; roiheight:
        dstlen = 1.5 * roiwidth
    else:
        dstlen = 1.5 * roiheight
​
    diff_xlen = dstlen - roiwidth
    diff_ylen = dstlen - roiheight
​
    newx = xmin
    newy = ymin
​
    imagerows, imagecols, channel = im.shape
    if newx &gt;= diff_xlen / 2 and newx + roiwidth + diff_xlen / 2 &lt; imagecols:
        newx = newx - diff_xlen / 2
    elif newx &lt; diff_xlen / 2:
        newx = 0
    else:
        newx = imagecols - dstlen
​
    if newy &gt;= diff_ylen / 2 and newy + roiheight + diff_ylen / 2 &lt; imagerows:
        newy = newy - diff_ylen / 2
    elif newy &lt; diff_ylen / 2:
        newy = 0
    else:
        newy = imagecols - dstlen
​
    roi = im[int(newy):int(newy + dstlen), int(newx):int(newx + dstlen), 0:3]
    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
    roiresized = cv2.resize(roi,
                            (testsize, testsize)).astype(np.float32) / 255.0
    imgblob = data_transforms(roiresized).unsqueeze(0)
    imgblob.requires_grad = False
    imgblob = Variable(imgblob)
    torch.no_grad()
    predict = F.softmax(net(imgblob))
    print(predict)
    index = np.argmax(predict.detach().numpy())
​
    im_show = cv2.imread(os.path.join(img_path, imagepath), 1)
    im_h, im_w, im_c = im_show.shape
    pos_x = int(newx + dstlen)
    pos_y = int(newy + dstlen)
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.rectangle(im_show, (int(newx), int(newy)),
                  (int(newx + dstlen), int(newy + dstlen)), (0, 255, 255), 2)
    if index == 0:
        cv2.putText(im_show, &#39;none&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
    if index == 1:
        cv2.putText(im_show, &#39;pout&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
    if index == 2:
        cv2.putText(im_show, &#39;smile&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
    if index == 3:
        cv2.putText(im_show, &#39;open&#39;, (pos_x, pos_y), font, 1.5, (0, 0, 255), 2)
#     cv2.namedWindow(&#39;result&#39;, 0)
#     cv2.imshow(&#39;result&#39;, im_show)
    cv2.imwrite(os.path.join(&#39;results&#39;, imagepath), im_show)
#     print(os.path.join(&#39;results&#39;, imagepath))
    plt.imshow(im_show[:, :, ::-1])  # 这里需要交换通道，因为 matplotlib 保存图片的通道顺序是 RGB，而在 OpenCV 中是 BGR
    plt.show()
#     cv2.waitKey(0)
# cv2.destroyAllWindows()
tensor([[8.1330e-03, 6.7033e-04, 9.8497e-01, 6.2311e-03]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[1.0822e-06, 1.9005e-09, 1.0000e+00, 2.3623e-07]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[9.9190e-01, 3.7207e-03, 4.3589e-03, 1.5936e-05]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[4.3434e-07, 1.2525e-06, 1.1251e-05, 9.9999e-01]],
       grad_fn=&lt;SoftmaxBackward&gt;)

tensor([[0.0899, 0.8970, 0.0115, 0.0016]], grad_fn=&lt;SoftmaxBackward&gt;)</code></pre><p>再次说明：0 代表 none、 1 代表pouting、2 代表 smile、3 代表 openmouth</p><p>上面展示的图片上方会有一个输出，如：tensor([[8.1330e-03, 6.7033e-04, 9.8497e-01, 6.2311e-03]])</p><p>这个代表的含义是，该图片在这个模型预测下，是该类别的可能性，比如上面这个例子 9.8497e-01 是四个值最大的，它的索引是 2（从 0 开始算），所以预测该图片为 smile</p><p>以上就是本训练营的全部内容了，希望通过本次训练营，可以帮助大家搭建起一个深度学习项目的框架，然后将所学的知识应用到自己的项目、工作中。谢谢！</p><p>– By：有三AI 团队</p><p>聚焦于让大家能够系统性地完成AI各个领域所需的专业知识的学习，实现三人行必有AI，三人行必有我师的愿景。</p></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2021-02-21 10:17:35" itemprop="dateModified" datetime="2021-02-21T10:17:35+08:00">2021-02-21</time> </span><span id="2021/01/29/深度学习_1_day/" class="item leancloud_visitors" data-flag-title="深度学习_1_day" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.jpg" alt="John Doe 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.jpg" alt="John Doe 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文博主： </strong>John Doe <i class="ic i-at"><em>@</em></i>Alan</li><li class="link"><strong>本文链接：</strong> <a href="http://47.97.229.110/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/" title="深度学习_1_day">http://47.97.229.110/2021/01/29/深度学习_1_day/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2-day/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva3.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclx29mstj20zk0m8hdt.jpg" title="深度学习_2_day"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 人工智能</span><h3>深度学习_2_day</h3></a></div><div class="item right"><a href="/2021/01/29/python-1-day/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva3.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipeyhsblkj20zk0m81kx.jpg" title="python_1_day"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> python</span><h3>python_1_day</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/" rel="bookmark" title="深度学习_1_day">深度学习_1_day</a></li><li><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2-day/" rel="bookmark" title="深度学习_2_day">深度学习_2_day</a></li><li><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3-day/" rel="bookmark" title="深度学习_3_day">深度学习_3_day</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="John Doe" data-src="/images/avatar.jpg"><p class="name" itemprop="name">John Doe</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">13</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">5</span> <span class="name">分类</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0FsYW5vc3k=" title="https:&#x2F;&#x2F;github.com&#x2F;Alanosy"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cDovL3d3dy56aGlodS5jb20vcGVvcGxlL3dhbmctemhlbmctODEtNDQtOTM=" title="http:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;wang-zheng-81-44-93"><i class="ic i-zhihu"></i></span> <span class="exturl item email" data-url="bWFpbHRvOkFsYW5vc0BhbGl5dW4uY29t" title="mailto:Alanos@aliyun.com"><i class="ic i-envelope"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20vdS83NTMwMzcwODEx" title="https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;7530370811"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;about.me&#x2F;yourname"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>links</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2-day/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2021/01/29/python-1-day/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="分类于 人工智能">人工智能</a></div><span><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_1_day/" title="深度学习_1_day">深度学习_1_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%97%A5%E5%BF%97/" title="分类于 日志">日志</a></div><span><a href="/2021/01/26/2020-1-26/" title="2020-1-26">2020-1-26</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="分类于 人工智能">人工智能</a></div><span><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_3-day/" title="深度学习_3_day">深度学习_3_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="分类于 人工智能">人工智能</a></div><span><a href="/2021/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_2-day/" title="深度学习_2_day">深度学习_2_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/python/" title="分类于 python">python</a></div><span><a href="/2021/01/29/python-2-day/" title="python_2_day">python_2_day</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2021/02/22/cheshi/" title="cheshi">cheshi</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/python/" title="分类于 python">python</a></div><span><a href="/2021/01/29/python-1-day/" title="python_1_day">python_1_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/hexo/" title="分类于 hexo">hexo</a></div><span><a href="/2021/01/26/hello-world/" title="Hello Hexo">Hello Hexo</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/python/" title="分类于 python">python</a></div><span><a href="/2021/01/29/python-3-day/" title="python_3_day">python_3_day</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%97%A5%E5%B8%B8/" title="分类于 日常">日常</a></div><span><a href="/2021/02/18/%E5%8F%AA%E8%A6%81%E4%BD%A0%E9%9C%80%E8%A6%81%E6%88%91%EF%BC%8C%E6%88%91%E6%B0%B8%E8%BF%9C%E5%9C%A8%E4%BD%A0%E7%9C%8B%E7%9A%84%E5%88%B0%E7%9A%84%E5%9C%B0%E6%96%B9/" title="只要你需要我，我永远在你看的到的地方">只要你需要我，我永远在你看的到的地方</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">John Doe @ Yume Shoka</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">143k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">2:10</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2021/01/29/深度学习_1_day/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->